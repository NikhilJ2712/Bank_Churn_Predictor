{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will evaluate the performance of the trained models. We will:\n",
    "1. Load the saved models and test data.\n",
    "2. Generate classification reports for each model.\n",
    "3. Plot confusion matrices.\n",
    "4. Plot ROC curves and compare AUC scores.\n",
    "5. Create a summary of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = np.load('X_test_processed.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "# Load models\n",
    "log_reg = joblib.load('logistic_regression_model.joblib')\n",
    "rf = joblib.load('random_forest_model.joblib')\n",
    "gb = joblib.load('gradient_boosting_model.joblib')\n",
    "xgb_clf = joblib.load('xgboost_model.joblib')\n",
    "best_rf = joblib.load('best_random_forest_model.joblib')\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb,\n",
    "    'XGBoost': xgb_clf,\n",
    "    'Tuned Random Forest': best_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confusion Matrices and Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'--- {name} ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Churned', 'Churned'], yticklabels=['Not Churned', 'Churned'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ROC Curves and AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Check if the model has predict_proba method\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else: # For models like SVM that might not have it by default\n",
    "        y_pred_proba = model.decision_function(X_test)\n",
    "        y_pred_proba = (y_pred_proba - y_pred_proba.min()) / (y_pred_proba.max() - y_pred_proba.min())\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance') # Dashed diagonal\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    performance_summary.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(performance_summary).set_index('Model')\n",
    "summary_df.sort_values(by='F1-Score', ascending=False, inplace=True)\n",
    "\n",
    "print('Model Performance Summary:')\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n\n",
    "The **Tuned Random Forest** model demonstrates the best overall performance, achieving the highest F1-Score and a strong AUC. This is critical for a churn problem, as the F1-score provides a balance between precision and recall, and recall is particularly important for identifying as many potential churners as possible.\n\n",
    "The base Random Forest and XGBoost models also show very competitive performance. The Gradient Boosting model is slightly behind them, and the Logistic Regression model, while a good baseline, is clearly outperformed by the more complex ensemble methods. Based on these results, the **Tuned Random Forest model is the recommended model** for this churn prediction task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
