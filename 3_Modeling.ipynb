{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build and train several machine learning models to predict customer churn. We will:\n",
    "1. Load the preprocessed data.\n",
    "2. Train a baseline Logistic Regression model.\n",
    "3. Train advanced models: Random Forest, Gradient Boosting, and XGBoost.\n",
    "4. Perform hyperparameter tuning on the best-performing model.\n",
    "5. Save the trained models for evaluation and future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_resampled.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train_resampled.npy', allow_pickle=True)\n",
    "X_test = np.load('X_test_processed.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Test data shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "print('--- Logistic Regression ---')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print('--- Random Forest ---')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print('--- Gradient Boosting ---')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print('--- XGBoost ---')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning (for Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the initial results, Random Forest seems to perform well. Let's try to tune it. We will use a small grid for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "print('\\n--- Tuned Random Forest ---')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_best_rf))\n",
    "print(classification_report(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(log_reg, 'logistic_regression_model.joblib')\n",
    "joblib.dump(rf, 'random_forest_model.joblib')\n",
    "joblib.dump(gb, 'gradient_boosting_model.joblib')\n",
    "joblib.dump(xgb_clf, 'xgboost_model.joblib')\n",
    "joblib.dump(best_rf, 'best_random_forest_model.joblib')\n",
    "\n",
    "print('Models saved successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
